}
# sanity check that these all equal the total
unique((p_degenerate+p_continuous+p_disjoint)==total)
p_degenerate <- p_degenerate/total
p_continuous <- p_continuous/total
p_disjoint <- p_disjoint/total
p_degenerate
p_continuous
p_disjoint
p_degenerate
# sanity check that these all equal the total
unique((p_degenerate+p_continuous+p_disjoint)==total)
d <- df1
head(d)
# get strategy proportions over time
iter1 <- subset(d,iteration==1)
head(iter1)
names(iter1)
d <- df1
# get strategy proportions over time
iter1 <- subset(d,iteration==1)
# initialize with the input to iteration 1
iter1 <- subset(d,iteration==1) #table(iter1$systype_input)
total <- c(length(iter1$participant)) # total number of systems (use for normalizing each p)
p_degenerate <- c(length(subset(iter1,systype_input=="degenerate")$participant))
p_continuous <- c(length(subset(iter1,systype_input=="continuous")$participant))
p_disjoint <- c(length(subset(iter1,systype_input=="disjoint")$participant))
# now use the output systems
for (i in 1:max(d$iteration)) {
iter <- subset(d,iteration==i)
total <- c(total,length(iter$participant))
p_degenerate <- c(p_degenerate,length(subset(iter,systype_input=="degenerate")$participant))
p_continuous <- c(p_continuous,length(subset(iter,systype_input=="continuous")$participant))
p_disjoint <- c(p_disjoint,length(subset(iter,systype_input=="disjoint")$participant))
}
# sanity check that these all equal the total
unique((p_degenerate+p_continuous+p_disjoint)==total)
p_degenerate <- p_degenerate/total
p_continuous <- p_continuous/total
p_disjoint <- p_disjoint/total
p_degenerate
p_continuous
p_disjoint
# plot the type of each catsys over time
time <- seq(1,length(total))
plot(time,p_degenerate,type="l",las=1,ylim=c(0,1),lty="dotted")
lines(time,p_continuous)
lines(time,p_disjoint,lty="twodash")
stability_dataframe <- function(df) {
}
df <- df1
all_system_types <- unique(df$system512)
all_system_types
df <- readRDS("../Data/experiment1.rds")
# subset to just look at the first 8 iterations
# there were just a couple iterations in the cultural condition that went over 8
# we toss those out because no one in the individual condition was allowed to go beyond 8 iterations
df <- subset(df,iteration<9)
table(df$iteration) # check
iteration <- c()        # generation (cultural condition) or round (individual condition) - this is the "age" of the category system
participant <- c()      # unique participant ID
lineage <- c()          # unique ID of the chain
skew <- c()             # S = one of the skewed frequency distributions, U = the uniform one
condition <- c()        # C = cultural, I = individual
trial <- c()            # test trial number (ranges 1 through 10)
RT <-c()                # time spent on the current test trial stim in milliseconds
stim_color <- c()       # greyscale code of the image in the current test trial
# df$testset values map to this array of greyscale colors:
greys <- c(25,50,75,100,125,150,175,200,225,250)
# ex: testset 0 = greyscale 25, testset 4 = greyscale 125
# 25 is almost black, 250 is almost white
stim_color_rescale <- c()  # this one rescales stim color to a 0-1 range
stim_frequency <- c()   # frequency of the stim in the current test trial during training (normalized 0 to 1)
L_counts <- c(10,5,4,3,2,2,1,1,1,1)  # frequency per stim in the left skew condition
L_counts <- L_counts/sum(L_counts)
R_counts <- rev(L_counts)            # frequency per stim in the right skew condition
# is the current stimulus on the edge of a category boundary? According to the category system people produced on that testing round.
# uses the function defined below system_to_bounded()
bounded <- c()          # 0 = no. Both neighbors to the stim have same category label as the stim.
system_to_bounded <- function(system_string) { # system = a string, ex: "1100000001"
result <- c() # result is an indexable array of binary digits
s <- as.numeric(strsplit(system_string, split="")[[1]])
m <- length(s)
# if the two labels are the same, assign 0. If the two lables are different, assign 1.
if ( s[1] == s[2] ) { result[1] <- 0 } else { result[1] <- 1 } # first one
if ( s[m] == s[m-1] ) { result[m] <- 0 } else { result[m] <- 1 } # last one
# if the three labels are the same, assign 0.  Otherwise, assign 1.
for (j in 2:(m-1)) { # the ones in the middle
if ( s[j] == s[j-1] && s[j] == s[j+1] ) { result[j] <- 0 } else { result[j] <- 1 }
}
return(result)
}
for (r in 1:length(df$X)) { # for each row in the original data frame (= the result of one round)
dis <- df[r,]$distribution
# get the elements to break up per test trial in the loop below
rts <- df[r,]$test_RTs
sti <- df[r,]$testset
# then break them up into an indexable array
rts <- as.numeric(strsplit(toString(rts),",")[[1]])
sti <- as.numeric(strsplit(toString(sti),",")[[1]])
bounded_codes <- system_to_bounded(toString(df[r,]$system512))
for (s in 1:10) { # for each stimulus in the testing set
# use as.character() to keep these as factors - otherwise they convert to numerics
lineage <- c(lineage,as.character(df[r,]$lineage))
participant <- c(participant, as.character(df[r,]$participant))
condition <- c(condition, as.character(df[r,]$condition))
iteration <- c(iteration, df[r,]$iteration)
trial <- c(trial,s)
if (dis == "U") { skew <- c(skew, "U") } else { skew <- c(skew, "S") }
RT <- c(RT, rts[s])
stim_color <- c(stim_color, greys[sti[s]+1]) # +1 coz testset starts at zero
# work out what the stim frequency was
if (dis == "L") { fre <- L_counts[sti[s]+1] }
if (dis == "R") { fre <- R_counts[sti[s]+1] }
if (dis == "U") { fre <- 3/30 }
stim_frequency <- c(stim_frequency, fre)
# pull out the bounded code
bounded <- c(bounded, bounded_codes[sti[s]+1])
}
}
# re-scale color from range 25-250 to 0-1
stim_color_rescale <- (stim_color-25)/225
d <- data.frame(lineage,iteration,participant,trial,stim_color,stim_color_rescale,stim_frequency,RT,bounded,skew,condition)
d$bounded <- as.factor(d$bounded)
# original data frame
length(unique(df$participant)) # 288 unique participants
length(unique(d$participant)) # 288 unique participants
length(unique(d$lineage)) # 135 unique lineages
require(lme4)
full <- glmer(bounded ~ stim_frequency * stim_color * skew * condition * iteration  + (1|participant) + (1|lineage), data=d, family = "binomial")
# Problem: model didn't converge!
# but you can still look at the outcome:
summary(full)
"Fixed effects:
Estimate Std. Error z value Pr(>|z|)
(Intercept)                                   -0.6245549  0.8936370  -0.699   0.4846
stim_frequency                                 3.0157247  5.3495232   0.564   0.5729
stim_color                                    -0.0015618  0.0053494  -0.292   0.7703
skewU                                          1.7636507  1.0571039   1.668   0.0952 .
condition                                     -0.0293868  0.5087619  -0.058   0.9539
iteration                                     -0.2937655  0.2396105  -1.226   0.2202
stim_frequency:stim_color                      0.0073400  0.0323565   0.227   0.8205
stim_color:skewU                              -0.0095965  0.0059212  -1.621   0.1051
stim_frequency:condition                      -1.0740860  3.0622923  -0.351   0.7258
stim_color:condition                           0.0028483  0.0030524   0.933   0.3508
skewU:condition                               -0.5663632  0.6077377  -0.932   0.3514
stim_frequency:iteration                      -0.7625273  1.6251765  -0.469   0.6389
stim_color:iteration                           0.0011168  0.0014579   0.766   0.4437
skewU:iteration                               -0.3482901  0.2593043  -1.343   0.1792
condition:iteration                            0.1846463  0.1332035   1.386   0.1657
stim_frequency:stim_color:condition           -0.0077485  0.0183283  -0.423   0.6725
stim_color:skewU:condition                     0.0036028  0.0034005   1.060   0.2894
stim_frequency:stim_color:iteration           -0.0108300  0.0101689  -1.065   0.2869
stim_color:skewU:iteration                     0.0037075  0.0015923   2.328   0.0199 *
stim_frequency:condition:iteration            -0.3931367  0.9127886  -0.431   0.6667
stim_color:condition:iteration                -0.0009712  0.0008165  -1.190   0.2343
skewU:condition:iteration                      0.0952511  0.1475952   0.645   0.5187
stim_frequency:stim_color:condition:iteration  0.0088872  0.0055617   1.598   0.1101
stim_color:skewU:condition:iteration          -0.0017167  0.0009090  -1.889   0.0589 ."
# save skewed data only in new data frame called "ds"
ds <- subset(d,skew=="S")
# sanity check that all the U data is dropped
table(d$skew)
table(ds$skew)
# new model
m2 <- glmer(bounded ~ stim_frequency * stim_color * condition * iteration + (1|participant) + (1|lineage), data=ds, family = "binomial")
summary(m2)
"Fixed effects:
Estimate Std. Error z value Pr(>|z|)
(Intercept)                                   -0.6210102  0.8865394  -0.700    0.484
stim_frequency                                 2.9489231  5.3330180   0.553    0.580
stim_color                                    -0.0015730  0.0053345  -0.295    0.768
condition                                     -0.0319201  0.5045854  -0.063    0.950
iteration                                     -0.2941240  0.2392897  -1.229    0.219
stim_frequency:stim_color                      0.0077603  0.0322427   0.241    0.810
stim_frequency:condition                      -1.0353655  3.0528485  -0.339    0.734
stim_color:condition                           0.0028459  0.0030436   0.935    0.350
stim_frequency:iteration                      -0.7367687  1.6214499  -0.454    0.650
stim_color:iteration                           0.0011372  0.0014558   0.781    0.435
condition:iteration                            0.1859119  0.1330055   1.398    0.162
stim_frequency:stim_color:condition           -0.0079708  0.0182621  -0.436    0.662
stim_frequency:stim_color:iteration           -0.0110023  0.0101500  -1.084    0.278
stim_frequency:condition:iteration            -0.4048206  0.9107453  -0.444    0.657
stim_color:condition:iteration                -0.0009802  0.0008152  -1.202    0.229
stim_frequency:stim_color:condition:iteration  0.0089676  0.0055509   1.615    0.106"
m3 <- glmer(bounded ~ stim_frequency * stim_color_rescale + (1|participant) + (1|lineage), data=ds, family="binomial")
summary(m3)
"                          Estimate Std. Error z value Pr(>|z|)
(Intercept)                -0.5713     0.1250  -4.572 4.83e-06 ***
stim_frequency             -2.9908     0.7008  -4.268 1.97e-05 ***
stim_color                  0.3438     0.1761   1.953   0.0509 .
stim_frequency:stim_color   1.8865     1.0771   1.751   0.0799 ."
# intercept:
# in the absence of variables' effects, a stim is more likely to be 0 (not be on a category boundary)
table(ds$bounded)
"
0     1
2479  1671
"
# stim_frequency on it's own:
# when that training frequency of a stim is higher, it is more likely to be 0 (NOT have a category boundary)
table(ds$stim_frequency)
"
0.0333  0.0666  0.1  0.1333  0.1666  0.3333
1660    830     415  415     415     415
"
table(ds$bounded,ds$stim_frequency)
"
0.0333  0.0666  0.1000  0.1333  0.1666  0.3333
0       999     424     254      274    229     299
1       661     406     161      141    186     116
"
table(ds$bounded,ds$stim_color)
"
25  50  75  100 125 150 175 200 225 250  <- stim color
0   329 257 261 254 217 207 222 232 213 287  <- stim not on category boundary
1   86  158 154 161 198 208 193 183 202 128  <- stim is on category boundary (looks non-linear with dip back down to 128 on brightest edge)
"
# Obviously I want to know how this boundaries evolve over time, so I want to know the effect of iteration.
m <- glmer(bounded ~ stim_frequency * stim_color * iteration + (1|participant) + (1|lineage), data=ds, family="binomial")
# And I also want to know the effect of condition in case the boundaries evolve differently in the two transmission regimes.
m <- glmer(bounded ~ stim_frequency * stim_color * condition + (1|participant) + (1|lineage), data=ds, family="binomial")
m
system_to_bounded <- function(system_string) { # system = a string, ex: "1100000001"
result <- c() # result is an indexable array of binary digits
s <- as.numeric(strsplit(system_string, split="")[[1]])
m <- length(s)
# if the two labels are the same, assign 0. If the two lables are different, assign 1.
if ( s[1] == s[2] ) { result[1] <- 0 } else { result[1] <- 1 } # first one
if ( s[m] == s[m-1] ) { result[m] <- 0 } else { result[m] <- 1 } # last one
# if the three labels are the same, assign 0.  Otherwise, assign 1.
for (j in 2:(m-1)) { # the ones in the middle
if ( s[j] == s[j-1] && s[j] == s[j+1] ) { result[j] <- 0 } else { result[j] <- 1 }
}
return(result)
}
system_to_bounded("1100000001")
df <- readRDS("../Data/experiment1.rds")
# subset to just look at the first 8 iterations
# there were just a couple iterations in the cultural condition that went over 8
# we toss those out because no one in the individual condition was allowed to go beyond 8 iterations
df <- subset(df,iteration<9)
table(df$iteration) # check
iteration <- c()        # generation (cultural condition) or round (individual condition) - this is the "age" of the category system
participant <- c()      # unique participant ID
lineage <- c()          # unique ID of the chain
skew <- c()             # S = one of the skewed frequency distributions, U = the uniform one
condition <- c()        # C = cultural, I = individual
trial <- c()            # test trial number (ranges 1 through 10)
RT <-c()                # time spent on the current test trial stim in milliseconds
stim_color <- c()       # greyscale code of the image in the current test trial
# df$testset values map to this array of greyscale colors:
greys <- c(25,50,75,100,125,150,175,200,225,250)
# ex: testset 0 = greyscale 25, testset 4 = greyscale 125
# 25 is almost black, 250 is almost white
stim_color_rescale <- c()  # this one rescales stim color to a 0-1 range
stim_frequency <- c()   # frequency of the stim in the current test trial during training (normalized 0 to 1)
L_counts <- c(10,5,4,3,2,2,1,1,1,1)  # frequency per stim in the left skew condition
L_counts <- L_counts/sum(L_counts)
R_counts <- rev(L_counts)            # frequency per stim in the right skew condition
# is the current stimulus on the edge of a category boundary? According to the category system people produced on that testing round.
# uses the function defined below system_to_bounded()
bounded <- c()          # 0 = no. Both neighbors to the stim have same category label as the stim.
system_to_bounded <- function(system_string) { # system = a string, ex: "1100000001"
result <- c() # result is an indexable array of binary digits
s <- as.numeric(strsplit(system_string, split="")[[1]])
m <- length(s)
# if the two labels are the same, assign 0. If the two lables are different, assign 1.
if ( s[1] == s[2] ) { result[1] <- 0 } else { result[1] <- 1 } # first one
if ( s[m] == s[m-1] ) { result[m] <- 0 } else { result[m] <- 1 } # last one
# if the three labels are the same, assign 0.  Otherwise, assign 1.
for (j in 2:(m-1)) { # the ones in the middle
if ( s[j] == s[j-1] && s[j] == s[j+1] ) { result[j] <- 0 } else { result[j] <- 1 }
}
return(result)
}
system_to_bounded("1100000001")
for (r in 1:length(df$participant)) { # for each row in the original data frame (= the result of one round)
dis <- df[r,]$distribution
# get the elements to break up per test trial in the loop below
rts <- df[r,]$test_RTs
sti <- df[r,]$testset
# then break them up into an indexable array
rts <- as.numeric(strsplit(toString(rts),",")[[1]])
sti <- as.numeric(strsplit(toString(sti),",")[[1]])
bounded_codes <- system_to_bounded(toString(df[r,]$system512))
for (s in 1:10) { # for each stimulus in the testing set
# use as.character() to keep these as factors - otherwise they convert to numerics
lineage <- c(lineage,as.character(df[r,]$lineage))
participant <- c(participant, as.character(df[r,]$participant))
condition <- c(condition, as.character(df[r,]$condition))
iteration <- c(iteration, df[r,]$iteration)
trial <- c(trial,s)
if (dis == "U") { skew <- c(skew, "U") } else { skew <- c(skew, "S") }
RT <- c(RT, rts[s])
stim_color <- c(stim_color, greys[sti[s]+1]) # +1 coz testset starts at zero
# work out what the stim frequency was
if (dis == "L") { fre <- L_counts[sti[s]+1] }
if (dis == "R") { fre <- R_counts[sti[s]+1] }
if (dis == "U") { fre <- 3/30 }
stim_frequency <- c(stim_frequency, fre)
# pull out the bounded code
bounded <- c(bounded, bounded_codes[sti[s]+1])
}
}
# re-scale color from range 25-250 to 0-1
stim_color_rescale <- (stim_color-25)/225
stim_color_rescale
d <- data.frame(lineage,iteration,participant,trial,stim_color,stim_color_rescale,stim_frequency,RT,bounded,skew,condition)
head(d)
d$bounded <- as.factor(d$bounded)
# original data frame
length(unique(df$participant)) # 288 unique participants
length(unique(d$participant)) # 288 unique participants
length(unique(d$lineage)) # 135 unique lineages
require(lme4)
full <- glmer(bounded ~ stim_frequency * stim_color * skew * condition * iteration  + (1|participant) + (1|lineage), data=d, family = "binomial")
# Problem: model didn't converge!
# but you can still look at the outcome:
summary(full)
# Problem: model didn't converge!
# but you can still look at the outcome:
summary(full)
# save skewed data only in new data frame called "ds"
ds <- subset(d,skew=="S")
# sanity check that all the U data is dropped
table(d$skew)
table(ds$skew)
# new model
m2 <- glmer(bounded ~ stim_frequency * stim_color * condition * iteration + (1|participant) + (1|lineage), data=ds, family = "binomial")
summary(m2)
require(lme4)
d1 <- readRDS("../Data/experiment1.rds")
d2 <- readRDS("../Data/experiment2.rds")
# restrict analyses to the first 8 iterations
d1 <- subset(d1,iteration < 9)
d2 <- subset(d2,iteration < 9)
# optimality score is based on Shannon entropy, H()
H <- function(X,base) { # X is a discrete probability distribution
X <- X[X != 0 ] # remove all zeros
return(-sum(X*log(X,base)))
}
# the probability distribution over stimuli in each of the three frequency conditions
# stimuli colors are a greyscale gradient ranging from darkest, i=1, to lightest, i=10, on the vectors below
Lmass <- c(10,5,4,3,2,2,1,1,1,1)/30    # the "dark/purple skew" condition  Lmass[1] is the darkest stimulus
Rmass <- rev(Lmass)                    # the "light/blue skew" condition
Umass <- rep(3,10)/30                  # the "uniform" condition
# define optimality score
# get vector of the mass under each category label, 0 and 1
# let the category system rack up points under any distribution of mass
scorer <- function(system,mass) {
sys <- as.numeric(strsplit(as.character(system),"")[[1]]) # system in df is one integer, turn to array of digits
mass_on_1 <- sum(sys*mass) # let each 1 rack up its corresponding mass
mass_on_0 <- 1-mass_on_1   # requires that all values in variable "mass" sums to one
return(H(c(mass_on_0,mass_on_1),2))
}
# example usage:
s <- d1$system512[1]  # example system is 1111110000
scorer(s,Lmass)       # H(0.1333333 0.8666667) = 0.5665094
# range of score
scorer("0000000000",Umass) # 0
scorer("1111100000",Umass) # 1
scorer("0000000000",Lmass) # 0
scorer("1100000000",Lmass) # 1 <- best possible optimality in L condition
add_optimality_cols <- function(df) {
HUmass <- c() # optimality score of each system under Umass - what the system's optimality would be if the distribution over stimuli were uniform
Hmass <- c()  # actual optimality score - what the optimality of the system was given the actual distribution over stimuli
HLmass <- c() # entropy of each system under Lmass
HRmass <- c() # entropy of each system under Rmass
for (i in 1:nrow(df)) {
HLmass <- c(HLmass,scorer(df$system512[i],Lmass))
HRmass <- c(HRmass,scorer(df$system512[i],Rmass))
HUmass <- c(HUmass,scorer(df$system512[i],Umass))
if (df$distribution[i]=="L") { Hmass <- c(Hmass,HLmass[i]) }
if (df$distribution[i]=="R") { Hmass <- c(Hmass,HRmass[i]) }
if (df$distribution[i]=="U") { Hmass <- c(Hmass,HUmass[i]) }
}
Hmass_diff <- Hmass-HUmass
# positive values mean optimality under the actual distribution is better than the uniform one
# negative values mean optimality is better under the uniform one
df <- cbind(df,Hmass,HUmass,Hmass_diff)
return(df)
}
d1 <- add_optimality_cols(d1)
d2 <- add_optimality_cols(d2)
# set reference variables
d1$distribution <- relevel(d1$distribution, ref="U") # make the uniform frequency condition the reference point
d1$condition <- relevel(d1$condition, ref="I") # make the individual transmission condition the reference point
full <- lmer(HUmass ~ distribution * condition * iteration + (1|lineage), data=d1, REML=FALSE)
reduce1 <- lmer(HUmass ~ distribution * condition + iteration + (1|lineage), data=d1, REML=FALSE)
reduce2 <- lmer(HUmass ~ distribution + condition * iteration + (1|lineage), data=d1, REML=FALSE)
reduce3 <- lmer(HUmass ~ distribution + condition + iteration + (1|lineage), data=d1, REML=FALSE)
anova(full,reduce1,reduce2,reduce3) # nothing is best, so no interactions are justified
r1 <- lmer(HUmass ~ distribution + condition + (1|lineage), data=d1, REML=FALSE)
anova(reduce3,r1) # keep iteration
r2 <- lmer(HUmass ~ distribution + iteration + (1|lineage), data=d1, REML=FALSE)
anova(reduce3,r2) # lose condition
r3 <- lmer(HUmass ~ condition + iteration + (1|lineage), data=d1, REML=FALSE)
anova(reduce3,r3) # lose distribution (was close: p = 0.08953)
best <- lmer(HUmass ~ iteration + (1|lineage), data=d1, REML=FALSE)
anova(full,best) # yep best is best coz full is not significantly better
summary(best) # result: iteration lowers optimality
"             Estimate Std. Error t value
(Intercept)  0.948664   0.009139  103.80
iteration   -0.012251   0.001888   -6.49"
summary(best) # result: iteration lowers optimality
anova(full,best) # yep best is best coz full is not significantly better
summary(best) # result: iteration lowers optimality
d2$distribution <- relevel(d2$distribution, ref="U") # make the uniform frequency condition the reference point
d2$condition <- relevel(d2$condition, ref="I") # make the individual transmission condition the reference point
full <- lmer(HUmass ~ distribution * condition * iteration + (1|lineage), data=d2, REML=FALSE)
reduce1 <- lmer(HUmass ~ distribution * condition + iteration + (1|lineage), data=d2, REML=FALSE)
reduce2 <- lmer(HUmass ~ distribution + condition * iteration + (1|lineage), data=d2, REML=FALSE)
reduce3 <- lmer(HUmass ~ distribution + condition + iteration + (1|lineage), data=d2, REML=FALSE)
anova(full,reduce1,reduce2,reduce3) # full is significantly better
# k that means we'll need to keep all the variables, but check each one anyway:
r1 <- lmer(HUmass ~ distribution + condition + (1|lineage), data=d2, REML=FALSE)
anova(full,r1) # keep iteration
r2 <- lmer(HUmass ~ distribution + iteration + (1|lineage), data=d2, REML=FALSE)
anova(full,r2) # keep condition
r3 <- lmer(HUmass ~ condition + iteration + (1|lineage), data=d2, REML=FALSE)
anova(full,r3) # keep distribution
summary(full)
"                                    Estimate Std. Error t value
(Intercept)                         0.940045   0.038689  24.298
distributionL                       0.068645   0.055265   1.242
distributionR                      -0.069291   0.055167  -1.256
conditionC                          0.034914   0.069342   0.504
iteration                          -0.016529   0.006465  -2.557 <- optimality goes down over time
distributionL:conditionC           -0.132659   0.097279  -1.364
distributionR:conditionC            0.084858   0.098784   0.859
distributionL:iteration            -0.026837   0.009769  -2.747
distributionR:iteration             0.001912   0.009751   0.196
conditionC:iteration               -0.011991   0.013670  -0.877
distributionL:conditionC:iteration  0.051853   0.018330   2.829
distributionR:conditionC:iteration -0.031394   0.020383  -1.540
"
d11 <- subset(d1,N_boundaries==1) # 266 systems with 1 boundary
d11$distribution <- relevel(d11$distribution, ref="U") # make the uniform frequency condition the reference point
d11$condition <- relevel(d11$condition, ref="C")
full <- lmer(HUmass ~ distribution * condition * iteration + (1|trajectory), data=d11, REML=FALSE)
reduce1 <- lmer(HUmass ~ distribution * condition + iteration + (1|trajectory), data=d11, REML=FALSE)
reduce2 <- lmer(HUmass ~ distribution + condition * iteration + (1|trajectory), data=d11, REML=FALSE)
reduce3 <- lmer(HUmass ~ distribution + condition + iteration + (1|trajectory), data=d11, REML=FALSE)
d11 <- subset(d1,N_boundaries==1) # 266 systems with 1 boundary
d11$distribution <- relevel(d11$distribution, ref="U") # make the uniform frequency condition the reference point
d11$condition <- relevel(d11$condition, ref="C")
full <- lmer(HUmass ~ distribution * condition * iteration + (1|lineage), data=d11, REML=FALSE)
reduce1 <- lmer(HUmass ~ distribution * condition + iteration + (1|lineage), data=d11, REML=FALSE)
reduce2 <- lmer(HUmass ~ distribution + condition * iteration + (1|lineage), data=d11, REML=FALSE)
reduce3 <- lmer(HUmass ~ distribution + condition + iteration + (1|lineage), data=d11, REML=FALSE)
anova(full,reduce1) # full wins
anova(full,reduce2) # full wins
anova(full,reduce3) # full wins
r1 <- lmer(HUmass ~ distribution * condition + (1|lineage), data=d11, REML=FALSE)
anova(full,r1) # full wins
r2 <- lmer(HUmass ~ distribution * iteration + (1|lineage), data=d11, REML=FALSE)
anova(full,r2) # full wins
r3 <- lmer(HUmass ~ condition * iteration + (1|lineage), data=d11, REML=FALSE)
anova(full,r3) # full wins
summary(full)
# boundary locations
require(stringr)
bound_location <- c()
for (i in 1:nrow(d11)) {
loc <- str_count(d11$system512[i],"1")
bound_location <- c(bound_location,loc)
}
d11 <- cbind(d11,bound_location)
##########################################################
# CULTURAL
# distribution L
s <- subset(d11,condition="C" & distribution=="L")
mean(s$Hmass) # 0.6360488
table(s$bound_location)/sum(table(s$bound_location))
head(d11)
table(s$bound_location)
s$condition
##########################################################
# CULTURAL
# distribution L
s <- subset(d11,condition=="C" & distribution=="L")
mean(s$Hmass) # 0.6360488
table(s$bound_location)/sum(table(s$bound_location))
table(s$bound_location)
##########################################################
# distribution L
s <- subset(d11,distribution=="L")
mean(s$Hmass) # 0.6360488
table(s$bound_location)/sum(table(s$bound_location))
table(s$bound_location)
# distribution U
s <- subset(d11,distribution=="U")
mean(s$Hmass) # 0.9033566
table(s$bound_location)/sum(table(s$bound_location))
table(s$bound_location)
# distribution R
s <- subset(d11,distribution=="R")
mean(s$Hmass) # 0.7209378
table(s$bound_location)/sum(table(s$bound_location))
table(s$bound_location)
s <- subset(d11,condition=="C")
mean(s$Hmass) # 0.6360488
table(s$bound_location)/sum(table(s$bound_location))
table(s$bound_location)
s <- subset(d11,condition=="I")
mean(s$Hmass) # 0.7437855
s <- subset(d11,condition=="I")
mean(s$Hmass) # 0.7738392
table(s$bound_location)/sum(table(s$bound_location))
table(s$bound_location)
as.vector(table(s$bound_location)/sum(table(s$bound_location)))
